---
title: Considerations for Large Authoritative DNS Servers Operators
abbrev: Considerations-Large-Auth-DNS-Ops  
docname: draft-moura-dnsop-authoritative-recommendations-08
date:

# stand_alone: true

ipr: trust200902
area: Internet
wg: DNSOP Working Group  
kw: Internet-Draft
cat: info

coding: us-ascii
pi:    # can use array (if all yes) or hash here
#  - toc
#  - sortrefs
#  - symrefs
  toc: yes
  sortrefs:   # defaults to yes
  symrefs: yes

author:
      -
        ins: G. C.M. Moura
        name: Giovane C. M. Moura
        org: SIDN Labs/TU Delft
        street: Meander 501
        city: Arnhem
        code: 6825 MD
        country: The Netherlands
        phone: +31 26 352 5500
        email: giovane.moura@sidn.nl
      -
        ins: W. Hardaker
        name: Wes Hardaker
        org: USC/Information Sciences Institute
        street: PO Box 382
        city: Davis
        code: 95617-0382
        country: U.S.A.
        phone:  +1 (530) 404-0099
        email: ietf@hardakers.net
      -
        ins: J. Heidemann
        name: John Heidemann
        org: USC/Information Sciences Institute
        street: 4676 Admiralty Way
        city: Marina Del Rey
        code: 90292-6695
        country: U.S.A.
        phone:  +1 (310) 448-8708
        email: johnh@isi.edu        
      -
       ins: M. Davids
       name: Marco Davids
       org: SIDN Labs
       city: Arnhem
       street: Meander 501
       code: 6825 MD
       country: The Netherlands
       phone: +31 26 352 5500
       email: marco.davids@sidn.nl        

normative:

  RFC2181:
  RFC1034:
  RFC7094:
  RFC1546:
  RFC1035:
  RFC1995:
  RFC5575:
  RFC5936:
  RFC4271:
  RFC4786:
  RFC1997:
  RFC8499:
  RFC6891:
  #I-D.ietf-dnsop-serve-stale:
#have to see how to add these references on rfcs
#https://tools.ietf.org/html/rfc7764#section-4.6
informative:


  Moura16b:
      target: https://www.isi.edu/~johnh/PAPERS/Moura16b.pdf
      title: Anycast vs DDoS Evaluating the November 2015 Root DNS Events.
      target: https://www.isi.edu/~johnh/PAPERS/Moura16b.pdf
      author:
        -
          name: Giovane C. M. Moura
        -
          name: Ricardo de O. Schmidt        
        -
          name: John Heidemann
        -
          name: Wouter de Vries

          name: Moritz Müller
        -
          name: Lan Wei
        -
          name: Cristian Hesselman
      date:  2016-10-14
      seriesinfo:
        ACM: 2016 Internet Measurement Conference
        DOI: /10.1145/2987443.2987446


  Schmidt17a:
      title: Anycast Latency - How Many Sites Are Enough. In Proceedings of the Passive and Active Measurement Workshop
      target: https://www.isi.edu/%7ejohnh/PAPERS/Schmidt17a.pdf
      author:
        -
          name: Ricardo de O. Schmidt        
        -
          name: John Heidemann
        -
          name: Jam Harm Kuipers
      date: March 2017      
      seriesinfo:
        PAM: Passive and Active Measurement Conference


  Moura18b:
    target: https://www.isi.edu/~johnh/PAPERS/Moura18b.pdf
    title: "When the Dike Breaks: Dissecting DNS Defenses During DDos"
    author:
     -
       name: Giovane C. M. Moura
     -
       name: John Heidemann
     -
       name: Moritz Mueller
     -
       name: Ricardo de O. Schmidt
     -
      name: Marco Davids

    date: 2018-10-31
    seriesinfo:
      ACM: 2018 Internet Measurement Conference
      DOI: 10.1145/3278532.3278534

  Moura19a:
        target: https://www.isi.edu/~johnh/PAPERS/Moura19b.pdf
        title: "Cache Me If You Can: Effects of DNS Time-to-Live"
        author:
         -
           name: Giovane C. M. Moura
         -
           name: John Heidemann
         -
           name: Ricardo de O. Schmidt
         -
           name: Wes Hardaker

        date: 2019-10-11
        seriesinfo:
          ACM: 2019 Internet Measurement Conference
          DOI: 10.1145/3355369.3355568

  Moura20a:
        target: https://www.isi.edu/~johnh/PAPERS/Moura20a.pdf
        title: "Old but Gold: Prospecting TCP to Engineer DNS Anycast (extended)"
        author:
         -
           name: Giovane C. M. Moura
         -
           name: John Heidemann
         -
           name: Wes Hardaker
         -
           name: Jeroen Bulten
         -
           name: Joao Ceron
         -
           name: Cristian Hesselman
           

        date: 2020-06-01
        seriesinfo:
          Technical Report ISI-TR-740
          USC/Information Sciences Institute.

          
  Moura20b:
        target: http://giovane-moura.nl/resources/paper/Moura20b.pdf
        title: " Clouding up the Internet: how centralized is DNS traffic becoming?"
        author:
         -
           name: Giovane C. M. Moura
         -
           name: Sebastian Castro
         -
           name: Wes Hardaker
         -
           name: Maarten Wullink
         -
           name: Cristian Hesselman

        date: 2020-10-27
        seriesinfo:
          ACM: 2020 Internet Measurement Conference
          DOI: 10.1145/3419394.3423625


  Sigla2014:
    title:   The Internet at the speed of light. In Proceedings of the 13th ACM
      Workshop on Hot Topics in Networks (Oct 2014)

    target: http://speedierweb.web.engr.illinois.edu/cspeed/papers/hotnets14.pdf
    author:
      -
        name: Ankit Singla
      -
        name: Balakrishnan Chandrasekaran
      -
        name: P Brighten Godfrey
      -
        name: Bruce Maggs
    seriesinfo:
        ACM:  Workshop on Hot Topics in Networks
    date: October 2014

  Vries17b:
    title: Verfploeter - Broad and Load-Aware Anycast Mapping
    target: https://www.isi.edu/%7ejohnh/PAPERS/Vries17b.pdf
    author:
     -
       name: Wouter de Vries
     -
       name: Ricardo de O. Schmidt       
     -
       name: Wes Hardaker
     -
       name: John Heidemann
     -
       name: Pieter-Tjerk de Boer    
     -
      name: Aiko Pras
    date: October 2017  
    seriesinfo:
      ACM: 2017 Internet Measurement Conference
      DOI: 10.1145/3131365.3131371


  Jung03a:
      title: Modeling TTL-based Internet caches
      target: http://www.ieee-infocom.org/2003/papers/11_01.PDF
      author:
       -
          name:  Jaeyeon Jung
       -
          name:  Arthur W. Berger
       -
          name: Hari Balakrishnan       
      date: July 2003   
      seriesinfo:
        ACM: 2003 IEEE INFOCOM
        DOI: 10.1109/INFCOM.2003.1208693


  RipeAtlas15a:
      title: RIPE Atlas A Global Internet Measurement Network
      target: http://ipj.dreamhosters.com/wp-content/uploads/issues/2015/ipj18-3.pdf
      author:
       -
          name: RIPE NCC Staff
      date: September 2015


  RipeAtlas19a:
          title: Ripe Atlas - RIPE Network Coordination Centre
          target: https://atlas.ripe.net/
          author:
             -
               name: RIPE NCC
          date: September 2019

  Mueller17b:
      title: Recursives in the Wild-  Engineering Authoritative DNS Servers.
      target: https://www.isi.edu/%7ejohnh/PAPERS/Mueller17b.pdf
      author:
       -
         name: Moritz Mueller
       -
         name: Giovane C. M. Moura
       -
         name: Ricardo de O. Schmidt         
       -
         name: John Heidemann
      date: October 2017   
      seriesinfo:
        ACM: 2017 Internet Measurement Conference
        DOI: 10.1145/3131365.3131366

  IcannHedge18:
          title: DNS-STATS -  Hedgehog 2.4.1
          target: http://stats.dns.icann.org/hedgehog/
          author:
            -
              name: ICANN
          date: October 2018     

  Ditl17:
          title: 2017 DITL data
          target: https://www.dns-oarc.net/oarc/data/ditl/2017
          author:
            -
              name: DNS OARC
          date: October 2018    

  Perlroth16:
          title: Hackers Used New Weapons to Disrupt Major Websites Across U.S.
          target: https://www.nytimes.com/2016/10/22/business/internet-problems-attack.html
          author:
            -
              name: Nicole Perlroth
          date: October 2016

  VerfSrc:
          title: Verfploeter source code
          target: https://github.com/Woutifier/verfploeter
          author:
            -
              name: Wouter de Vries
          date: November 2018

  AnyTest:
          title: Anycast Testbed
          target: http://www.anycast-testbed.com/
          author:
            -
                name: Ricardo de O. Schmidt
          date: December 2018
--- abstract

Recent research work has explored the deployment characteristics and
configuration of the Domain Name System (DNS).  This document
summarizes the conclusions from these research efforts and offers
specific, tangible advice to operators when configuring authoritative
DNS servers.

It is possible that the results presented in this document could be
applicable in a wider context than just the DNS protocol,
as some of the results may generically apply to
any stateless/short-duration, anycasted service.

This document is not an IETF consensus document: it is published for
informational purposes.


--- middle

Introduction    {#intro}
============

This document summarizes recent research work that explored the
deployed DNS configurations and offers derived, specific tangible
advice to DNS authoritative server operators (DNS operators
hereafter).  The considerations (C1–C5) presented in this document are
backed by published research work, which used wide-scale Internet
measurements to draw their conclusions. This document summarizes the
research results and describes the resulting key engineering options.
In each section, it points readers to the pertinent publications where
additional details are presented.

These considerations are designed for operators of "large"
authoritative DNS servers. In this context, "large" authoritative
servers refers to those with a significant global user population,
like top-level domain (TLD) operators, run by either a single or
multiple operators.  Typically these networks are deployed on wide
anycast networks {{RFC1546}}. These considerations may not be
appropriate for smaller domains, such as those used by an organization
with users in one unicast network, or in one city or region, where
operational goals such as uniform, global low latency are less
required.

It is possible that the results presented in this document could be
applicable in a wider context than just the DNS protocol, as some of
the results may generically apply to any stateless/short-duration,
anycasted service.  Because the conclusions of the reviewed studies
don't measure smaller networks, the wording in this document
concentrates solely on disusing large-scale DNS authoritative services
only.

This document is not an IETF consensus document: it is published for
informational purposes.

# Background


The DNS has main two types of DNS servers: authoritative servers and
recursive resolvers, shown by a representational deployment model in
{{recuath}}.  An authoritative server (shown as AT1--AT4 in
{{recuath}}) knows the content of a DNS zone, and is responsible for
answering queries about that zone.  It runs using local (possibly
automatically updated) copies of the zone and does not need to query
other servers {{RFC2181}} in order to answer requests. A recursive
resolver (Re1--Re3) is a server that iteratively queries authoritative
and other servers to answer queries received from client requests
{{RFC1034}}. A client typically employs a software library called a stub
resolver (stub in {{recuath}}) to issue its query to the upstream
recursive resolvers {{RFC1034}}.

            +-----+  +-----+  +-----+  +-----+
            | AT1 |  | AT2 |  | AT3 |  | AT4 |
            +-----+  +-----+  +-----+  +-----+
              ^         ^        ^        ^
              |         |        |        |
              |      +-----+     |        |
              +------| Re1 |----+|        |
              |      +-----+              |
              |         ^                 |
              |         |                 |
              |      +----+   +----+      |
              +------|Re2 |   |Re3 |------+
                     +----+   +----+
                       ^          ^
                       |          |
                       | +------+ |
                       +-| stub |-+
                         +------+
{: #recuath title="Relationship between recursive resolvers (Re) and authoritative name servers (ATn)"}

DNS queries issued by a client contribute to a user's perceived
perceived latency and affect user experience {{Sigla2014}} depending
on how long it takes for responses to be returned.  The DNS system has
been subject to repeated Denial of Service (DoS) attacks (for example,
in November 2015 {{Moura16b}}) in order to specifically degrade user
experience.

To reduce latency and improve resiliency against DoS attacks, the DNS
uses several types of service replication. Replication at the
authoritative server level can be achieved with (i) the deployment of
multiple servers for the same zone {{RFC1035}} (AT1---AT4 in
{{recuath}}), (ii) the use of IP anycast
{{RFC1546}}{{RFC4786}}{{RFC7094}} that allows the same IP address to
be announced from multiple locations (each of referred to as an
"anycast instance" {{RFC8499}}) and (iii) the use of load balancers to
support multiple servers inside a single (potentially anycasted)
instance. As a consequence, there are many possible ways an
authoritative DNS provider can engineer its production authoritative
server network, with multiple viable choices and no necessarily single
optimal design.

In the next sections we cover the specific consideration (C1--C5) for
conclusions drawn within the academic papers about large authoritative
DNS server operators.

# C1: Deploy anycast in every authoritative server for better load distribution {#c1}

Authoritative DNS server operators announce their service using NS
records{{RFC1034}}. Different authoritative servers for a given zone
should return the same content; typically they stay synchronized using
DNS zone transfers (AXFR{{RFC5936}} and IXFR{{RFC1995}}), coordinating
the zone data they all return to their clients.

DNS heavily relies upon replication to support high reliability,
ensure capacity and to reduce latency {{Moura16b}}. DNS has two
complementary mechanisms for service replication. First, the DNs
protocol itself supports nameserver replication through the use of
multiple nameserver records (NS records), each operating on different
IP addresses. Second, each of these addresses can run at multiple
physical locations through the use of IP
anycast{{RFC1546}}{{RFC4786}}{{RFC7094}}, by announcing the same IP
address from each instance at multiple locations -- Internet routing
(BGP{{RFC4271}}) associates the service's clients with their
topologically nearest anycast instance. Outside the DNS protocol,
replication can also be achieved by deploying load balancers at each
physical location. Nameserver replication is strongly recommended for
all zones (multiple NS records). IP anycast is used by many large
zones such as the DNS Root, most top-level domains{{Moura16b}} and
many large commercial enterprises, governments and other
organizations.

Most DNS operators strive to reduce service latency for users.
However, because they only have control over their authoritative
servers, and not over the client recursive resolvers, it is difficult
to ensure that recursives will be served by the closest authoritative
server. Server selection is up to the recursive resolver's software
implementation, and different vendors and even different releases
employ different criteria to chose the authoritative servers with
which to communicate.

Understanding how recursive resolvers choose authoritative servers is
a key step in improving the effectiveness of authoritative server
deployments. To measure and evaluate server deployments,
{{Mueller17b}} deployed seven unicast authoritative name servers in
different global locations and then queried them from more than 9000
RIPE authoritative server operators and their respective recursive
resolvers.
<!-- wjh: this last sentence doesn't make sense -->

{{Mueller17b}} found that recursive resolvers in the wild query all
available authoritative servers, regardless of the observed
latency. But the distribution of queries tends to be skewed towards
authoritatives with lower latency: the lower the latency between a
recursive resolver and an authoritative server, the more often the
recursive will send queries to that server. These results were
obtained by aggregating results from all of the vantage points and
were not specific to any specific vendor or version.

The authors believe this behavior is a consequence of combining the
two main criteria employed by resolvers when selecting authoritative
servers: resolvers regularly check all listed authoritative servers in
an NS set to determine which is closer (the least latent) and when one
isn't available selects one of the alternatives.

For an authoritative DNS operator, this result means that the latency
of all authoritative servers (NS records) matter, so they all must be
similarly capable -- all available authoritatives will be queried by
most recursive resolvers. Unicasted services, unfortunately, cannot
deliver good latency worldwide (a unicast authoritative server in
Europe will always have high latency to resolvers in California and
Australia, for example, given its geographical
distance). {{Mueller17b}} recommends that DNS operators deploy equally
strong IP anycast instances for every authoritative server (i.e., for
each NS record).  Each large authoritative DNS server provider should
phase out their usage of unicast and deploy a well engineered number
of anycast instances with good peering strategies so they can provide
good latency to their global clients. 
<!-- This doesn't really say anything?  what arch considerations?
However, {{Mueller17b}} also
notes that DNS operators should take architectural considerations
into account when planning for deploying anycast {{RFC1546}}.
-->

As a case study, the ".nl" TLD zone was originally served on seven
authoritative servers with a mixed unicast/anycast setup.  In early
2018, .nl moved to a setup with 4 anycast authoritative
servers. 
<!-- XXX: NEED TO SHOW/DESCRIBE RESULTS -->

{{Mueller17b}}'s contribution to DNS service engineering shows that
because unicast cannot deliver good latency worldwide, anycast needs
to be used to provide a low latency service worldwide.

# C2: Routing can matter more than locations

When selecting an anycast DNS provider or setting up an anycast
service, choosing the best number of anycast instances{{RFC4786}} to
deploy is a challenging problem.  Selecting where and how many global
locations to announce from using BGP is tricky.  Intuitively, one
could naively think that the more instances the better and simply
"more" will always lead to shorter response times.

This is not necessarily true, however. In fact, {{Schmidt17a}} found
that proper route engineering can matter more than the total number of
locations. They analyzed the relationship between the number of
anycast instances and service performance (measuring latency of the
round-trip time (RTT)), measuring the overall performance of four DNS
Root servers. The Root DNS servers are implemented by 12 separate
organizations serving the DNS root zone at 13 different IPv4/IPv6
address pairs.

The results documented in {{Schmidt17a}} measured the performance of
the {c,f,k,l}.root-servers.net (hereafter, "C", "F", "K" and "L")
servers from more than 7.9k RIPE Atlas probes. RIPE Atlas is a
Internet measurement platform with more than 12000 global vantage
points called "Atlas Probes" -- it is used regularly by both
researchers and operators {{RipeAtlas15a}} {{RipeAtlas19a}).

{{Schmidt17a}} found that the C server, a smaller anycast deployment
consisting of only 8 instances, provided very similar overall
performance in comparison to the much larger deployments of K and L,
with 33 and 144 instances respectively. The median RTT for C, K and L
root server were all between 30-32ms.

XXX: what about F???  why is it mentioned above if we don't talk about it?

Because RIPE Atlas is known to have better coverage in Europe than
other regions, the authors specifically analyzed the results per
region and per country (Figure 5 in {{Schmidt17a}}), and show that
known Atlas bias toward Europe does not change the conclusion that
properly selected anycast locations is more important to latency than
the number of sites.

The important conclusion of {{Schmidt17a}} is that when engineering
anycast services for performance, factors other than just the number
of instances (such as local routing connectivity) must be considered.
They showed that 12 instances can provide reasonable latency, assuming
they are globally distributed and have good local
interconnectivity. However, additional instances can still be useful
for other reasons, such as when handling Denial-of-service (DoS)
attacks {{Moura16b}}.


# C3: Collecting anycast catchment maps to improve design

An anycast DNS service may be deployed from several to more than one
hundred locations (for example, l.root-servers.net has over 150
anycast instances at the time this was written). Anycast leverages
Internet routing to distribute the incoming queries to a service's
distributed anycast locations; in theory, BGP (the Internet's de facto
routing protocol) forwards incoming queries to a nearby anycast
location (in terms of BGP distance). However, usually queries are not
evenly distributed across all anycast locations, as found in the case
of L-Root {{IcannHedge18}}.

Adding locations to an anycast service may change the load distribution across all locations. Given that BGP maps clients to locations, whenever a new location is announced, this new location may receive more or less traffic than it was engineered for, leading to suboptimal usage of the service or even stressing the new location while leaving others underutilized. This is a scenario that operators constantly face when expanding an anycast service. Besides, when setting up a new anycast service location, operators cannot directly estimate the query distribution among the locations in advance of enabling the new location.

To estimate the query loads across locations of an expanding service or a when setting up an entirely new service, operators need detailed anycast maps and catchment estimates (i.e., operators need to know which prefixes will be matched to which anycast instance). To do that, {{Vries17b}} developed a new technique enabling operators to carry out active measurements, using an open-source tool called Verfploeter (available at [VerfSrc]). Verfploeter maps a large portion of the IPv4 address space, allowing DNS operators to predict both query distribution and clients catchment before deploying new anycast instances. At the moment of this writing, Verfploeter still does not support IPv6.

{{Vries17b}} shows how this technique was used to predict both the catchment and query load distribution for the new anycast service of B-Root. Using two anycast instances in Miami (MIA) and Los Angeles (LAX) from the operational B-Root server, they sent ICMP echo packets to IP addresses to each IPv4 /24 on the Internet using a source address within the anycast prefix. Then, they recorded which instance the ICMP echo replies arrived at based on the Internet's BGP routing. This analysis resulted in an Internet wide catchment map. Weighting was then applied to the incoming traffic prefixes based on of 1 day of B-Root traffic (2017-04-12, DITL datasets {{Ditl17}}). The combination of the created catchment mapping and the load per prefix created an estimate predicting that 81.6% of the traffic would go to the LAX location. The actual value was 81.4% of traffic going to LAX, showing that the estimation was pretty close and the Verfploeter technique was a excellent method of predicting traffic loads in advance of a new anycast instance deployment ({{Vries17b}} also uses the term anycast site to refer to anycast location).

Besides that, Verfploeter can also be used to estimate how traffic shifts among locations when BGP manipulations are executed, such as AS Path prepending that is frequently used by production networks during DDoS attacks. A new catchment mapping for each prepending configuration configuration: no prepending, and prepending with 1, 2 or 3 hops at each instance. Then, {{Vries17b}} shows that this mapping can accurately estimate the load distribution for each configuration.

An important operational takeaway from {{Vries17b}} is that DNS operators can make informed choices when engineering new anycast locations or when expending new ones by carrying out active measurements using Verfploeter in advance of operationally enabling the fully anycast service. Operators can spot sub-optimal routing situations early, with a fine granularity, and with significantly better coverage than using traditional measurement platforms such as RIPE Atlas.

 To date, Verfploeter has been deployed on B-Root{{Vries17b}}, on a operational testbed (Anycast testbed) {{AnyTest}}, and on a large unnamed operator.

The consideration is therefore to deploy a small test Verfploeter-enabled platform in advance at a potential anycast locations may reveal the realizable benefits of using that location as an anycast interest, potentially saving significant financial and labor costs of deploying hardware to a new location that was less effective than as had been hoped.

# C4: When under stress, employ two strategies

DDoS attacks are becoming bigger, cheaper, and more frequent {{Moura16b}}. The most powerful recorded DDoS attack to DNS servers to date reached 1.2 Tbps, by using IoT devices {{Perlroth16}}. Such attacks call for an answer for the following question: how should a DNS operator engineer its anycast authoritative DNS server react to the stress of a DDoS attack? This question is investigated in study {{Moura16b}} in which empirical observations are grounded with the following theoretical evaluation of options.

An authoritative DNS server deployed using anycast will have many server instances distributed over many networks. Ultimately, the relationship between the DNS provider's network and a client's ISP will determine which anycast instance will answer queries for a given client, given that BGP is the protocol that maps clients to specific anycast instances by using routing information \[RF:KDar02\]. As a consequence, when an anycast authoritative server is under attack, the load that each anycast instance receives is likely to be unevenly distributed (a function of the source of the attacks), thus some instances may be more overloaded than others which is what was observed analyzing the Root DNS events of Nov. 2015 {{Moura16b}}. Given the fact that different instances may have different capacity (bandwidth, CPU, etc.), making a decision about how to react to stress becomes even more difficult.

In practice, an anycast instance under stress, overloaded with incoming traffic, has two options:


* It can withdraw or pre-prepend its route to some or to all of its neighbors, perform other traffic shifting tricks (such as reducing the propagation of its announcements using BGP communities{{RFC1997}}) which shrinks portions of its catchment), use FlowSpec {{RFC5575}} or other upstream communication mechanisms to deploy upstream filtering. The goals of these techniques is to perform some combination of shifting of both legitimate and attack traffic to other anycast instances (with hopefully greater capacity) or to block the traffic entirely.


* Alternatively, it can be become a degraded absorber, continuing to operate, but with overloaded ingress routers, dropping some incoming legitimate requests due to queue overflow. However, continued operation will also absorb traffic from attackers in its catchment, protecting the other anycast instances.


{{Moura16b}} saw both of these behaviors in practice in the Root DNS events, observed through instance reachability and route-trip time (RTTs). These options represent different uses of an anycast deployment. The withdrawal strategy causes anycast to respond as a waterbed, with stress displacing queries from one instance to others. The absorption strategy behaves as a conventional mattress, compressing under load, with some queries getting delayed or dropped.

Although described as strategies and policies, these outcomes are the result of several factors: the combination of operator and host ISP routing policies, routing implementations withdrawing under load, the nature of the attack, and the locations of the instances and the attackers. Some policies are explicit, such as the choice of local-only anycast instances, or operators removing an instance for maintenance or modifying routing to manage load. However, under stress, the choices of withdrawal and absorption can also be results that emerge from a mix of explicit choices and implementation details, such as BGP timeout values.

{{Moura16b}} speculates that more careful, explicit, and automated management of policies may provide stronger defenses to overload. For DNS operators, that means that besides traditional filtering, two other options are available (withdraw/prepend/communities or isolate instances), and the best choice depends on the specifics of the attack.


Note that this consideration refers to the operation of one anycast service, i.e., one anycast NS record. However, DNS zones with multiple authoritative anycast servers may expect load to spill from one anycast server to another, as resolvers switch from authoritative to authoritative when attempting to resolve a name {{Mueller17b}}.


# C5: Consider longer time-to-live values whenever possible


Caching is the cornerstone of good DNS performance and reliability. A 15 ms response to a new DNS query is fast, but a 1 ms cache hit to a repeat query is far faster. Caching also protects users from short outages and can mute even significant DDoS attacks {{Moura18b}}.

DNS record TTLs (time-to-live values) directly control cache duration {{RFC1034}}{{RFC1035}}
and, therefore, affect latency, resilience, and the role of DNS in CDN server selection. Some early work modeled caches as a function of their TTLs {{Jung03a}}, and recent work examined their interaction with DNS{{Moura18b}}, but no research provides considerations about what TTL values are good. With this goal Moura et. al. {{Moura19a}} carried out a measurement study investigating TTL choices and its impact on user experience in the wild, and not focused on specific resolvers (and their caching architectures), vendors, or setups.

First, they identified several reasons why operators/zone owners may want to choose longer or shorter TTLs:

  * Longer TTL leads to longer caching, which results in faster responses, given that cache hits are faster than cache misses in resolvers. {{Moura19a}} shows that the increase in the TTL for .uy TLD from 5 minutes (300s) to 1 day (86400s) reduced the latency from 15k Atlas vantage points significantly: the median RTT went from 28.7ms to 8ms, while the 75%ile decreased from 183ms to 21ms.

  * Longer caching results in lower DNS traffic: authoritative servers will experience less traffic if TTLs are extended, given that repeated queries will be answered by resolver caches.

  * Longer caching results in lower cost if DNS is metered: some DNS-As-A-Service providers charges are metered, with a per query cost (often added to a fixed monthly cost).

  * Longer caching is more robust to DDoS attacks on DNS: DDoS attacks on a DNS service provider harmed several prominent websites {{Perlroth16}}. Recent work has shown that DNS caching can greatly reduce the effects of DDoS on DNS, provided caches last longer than the attack {{Moura18b}}.


  * Shorter caching supports operational changes: An easy way to transition from an old server to a new one is to change the DNS records.
 Since there is no method to remove cached DNS records,
  the TTL duration represents a necessary transition delay to fully shift to a new server,
   so low TTLs allow more rapid transition.
 However, when deployments are planned in advance (that is, longer than the TTL),
  then TTLs can be lowered ''just-before'' a major operational change,
  and raised again once accomplished.

  * Shorter caching can help with a DNS-based response to DDoS attacks: Some DDoS-scrubbing services use DNS to redirect traffic during an attack. Since DDoS attacks arrive unannounced, DNS-based traffic redirection requires the TTL be keptquite low at all times to be ready to respond to a potential attack.


  * Shorter caching helps DNS-based load balancing: Many large services use DNS-based load balancing. Each arriving DNS request provides an opportunity to adjust load, so short TTLs may be desired to react more quickly to traffic dynamics. (Although many recursive resolvers have minimum caching times of tens of seconds, placing a limit on agility.)


As such, choice of TTL depends in part on external factors so no single recommendation is appropriate for all. Organizations must weigh these trade-offs to find a good balance. Still, some guidelines can be used when choosing TTLs:

  * For general users, {{Moura19a}} recommends longer TTLs, of at least one hour,
  and ideally 8, 12, or 24 hours. Assuming planned maintenance can be scheduled at least a day in advance,  long TTLs have little cost.

  * For TLD operators: TLD operators that allow public registration of domains (such as most ccTLDs and .com, .net, .org) host, in their zone
files, NS records (and glues if in-bailiwick) of their respective domains. {{Moura19a}} shows that most resolvers will use TTL values provided by the child delegations, but some will choose the TTL provided by the parents. As such, similarly to general users, {{Moura19a}} recommends longer TTLs for NS records of their delegations (at least one hour, preferably more).

  * Users of DNS-based load balancing or DDoS-prevention may require short TTLs: TTLs may be as short as 5 minutes, although 15 minutes may provide sufficient agility for many operators.
 Shorter TTLs here help agility; they are are an exception to the consideration for longer TTLs.

  * Use A/AAAA and NS records:  TTLs of A/AAAA records should be shorter or equal to the TTL for NS records for in-bailiwick authoritative DNS servers, given that the authors {{Moura19a}} found that, for such scenarios, once NS record expires, their associated A/AAAA will also be updated (glue is sent by the parents).  For out-of-bailiwick servers,  A and NS records are usually cached independently,  so different TTLs, if desired, will be effective. In either case, short A and AAAA records may be desired if  DDoS-mitigation services are an option.

  
  
# C6: Leverage DNS TCP traffic improve design and detect routing leaks

   XXX: @Wes: I added this section based on the new tech report, but have not changed it in the rest of the text, so if we decide to keep it, we need to include it in the intro and other places -- giovane 2021-02-17
   
   
RFC1035 {{RFC1035}}  states that DNS  servers should support both UDP and TCP as transport protocols.
DNS traffic over TCP (DNS/TCP hereafter) is typically used for DNS  zone transfers {{RFC5936}} and to transmit large  DNS responses, such as when they are large than the client's advertised EDNS(0) buffer{{RFC6891}} ( authoritative servers truncate UDP responses if  they are large than the resolver's EDNS(0) buffer size, and the resolvers are expected to re-query using TCP, which has built-in mechanisms that allows to handle large messages).

DNS/TCP traffic  it still can be useful in the design of authoritative services: it provides the authoritative server with the chance to measure round-trip times between to resolvers -- which is not available using  DNS/UDP. For example, the RTT can be measured during the TCP handshake, by calculating the time in between the arrival of the SYN packet, and the ACK  packet  that ACKS thet SYN-ACK response.


Currenlty, most of DNS traffic between resolvers and authoritative servers is still UDP {{Moura20a}}. For example, for the .nl country-code top-level domain (ccTLD), 2-6% of the traffic is TPC, depending on which authoritative server and if it is over IPv4 or IPv6.  However, this traffic comes from 20--23% of all resolvers, and 45% of the Autonomous Systems.  As such, the coverage is large in terms of resolvers and ASes than in terms of individual queries. 


Still, given the DNS traffic at authoritative servers is heavily skewed  -- 1/3 of traffic to .nl and .nz come from 5 cloud/content providers {{Moura20b}} -- it may not be needed to measure all prefixes  on the Internet (as Verfploeter{{Vries17b}} does with IPv4): only the ones that send most queries. For .nl, 96% of DNS queries come from ASes that also use DNS/TCP {{Moura20a}}.

Given that, {{Moura20a}} shows that DNS/TCP provides enough coverage to measure most clients ASes of the .nl ccTLD authoritative servers. They have also shown that DNS/UDP and DNS/TCP RTT area comparable for the same servers, and extracted in near-real time RTT from DNS/TCP traffic. Then, they applied it to analyze traffic per anycast server and location and per client AS. 

By doing that, they were able to identify that Google (AS15169) and Microsoft (AS8075) were polarized, i.e., they could only reach one anycast site of one of their anycast servers. They found this by observing DNS/TCP RTTs between these ASes and the authoritative servers. That trigger then to carry out BGP manipulations to remove this polarization, ultimately reducing the latency in 90% for Google.

Also, by monitoring RTTs, they were able to detect route leaks when suddenly one of the anycast sites start to experience a surge in RTT, given EU traffic was sent to Australia after a Tier1 ISP propagated by mistake.

DNS/TCP RTT also works well with IPv6 (while Verfploeter  does not) and measure real clients. 
As such, we recomment authoritative server operators to leverage RTT measurements from DNS/TCP to troubleshoot and improve design of their services. 




# Security considerations

As this document discusses applying research results to operational
deployments, there are no further security considerations, other than
the ones mentioned in the normative references.  Most of the
considerations affect mostly operational practice, though a few do
have security related impacts, which we'll summarize at high level.

Specifically, C4 discusses a few strategies to employ when a service
is under stress, providing operators with additional guidance when
handling denial of service attacks.

Similarly, C5 identifies both the operational and security benefits to
using longer time-to-live values.

<!-- verified against RFC3552 - MD -->

# Privacy Considerations

<!-- Add some remarkt according to RFC6973. Or should we name this "Human Rights considerations" according to RFC8280 - MD -->

This document does not add any practical new privacy issues, aside
from possible benefits in deploying longer TTLs as suggested in C5.
Longer TTLs may help preserve a user's privacy by reducing the number
of requests that get transmitted in both thec lient-to-resolver and
resolver-to-authoritative cases.

DNS privacy is currently under active study, and future research
efforts by multiple organizations may produce more guidance in this
area.

# IANA considerations

This document has no IANA actions.
<!-- RFC8126 style - MD -->

# Acknowledgements

This document is a summary of the main considerations of six research works referred in this document. As such, they were only possible thanks to the hard work of the authors of these research works.


   * Ricardo de O. Schmidt

   * Wouter B de Vries

   * Moritz Müller

   * Lan Wei

   * Cristian  Hesselman

   * Jan Harm Kuipers

   * Pieter-Tjerk de Boer

   * Aiko Pras

We would like also to thank the various reviewers of different versions of this draft: Duane Wessels, Joe Abley, Töma Gavrichenkov, John Levine, Michael StJohns, Kristof Tuyteleers, Stefan Ubbink, Klaus Darilion and Samir Jafferali, and comments provided at the IETF DNSOP session (IETF104).

Besides those, we would like thank those who have been individually thanked in each research work, RIPE NCC and DNS OARC for their tools and datasets used in this research, as well as the funding agencies sponsoring the individual research works.
